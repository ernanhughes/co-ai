# stephanie/data/plan_trace.py

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Union
# Assuming ScoreBundle exists in your codebase
# from stephanie.scoring.score_bundle import ScoreBundle
# If ScoreBundle is not directly importable here, we can use a Dict[str, Any] as a placeholder
# or define a minimal version. Let's assume it's available or use a generic dict for now.
# For self-containment in this snippet, let's define a minimal placeholder if needed.
try:
    from stephanie.scoring.score_bundle import ScoreBundle
except ImportError:
    # Minimal placeholder if the real one isn't available for import here
    # In practice, you would use the real ScoreBundle class
    ScoreBundle = Dict[str, Any] 
    # Note: This is just for type hinting if the real import fails in this context.
    # The actual data passed should be the real ScoreBundle object/dict.

# Similarly, for ExecutionStep, if it's not a simple dict
# from stephanie.data_structures.execution_step import ExecutionStep # Hypothetical
# We can define it here or assume it's a dict with specific keys.

@dataclass
class ExecutionStep:
    """
    Represents a single step in the execution of a reasoning plan.
    This can be generated by an executor like EpistemicPlanExecutorAgent.
    """
    step_id: Union[str, int] # Unique identifier for the step (e.g., index, name)
    description: str # A textual description of what this step does
    output_text: str # The textual output or result of this step
    
    # The scores assigned to this step's output by various scorers (SICQL, EBT, etc.)
    # against the original goal. 
    scores: ScoreBundle 

    # Optional: Embedding of the output_text. Can be computed on demand if not stored.
    output_embedding: Optional[List[float]] = None 
    
    # Optional: Any other metadata specific to this step
    meta: Dict[str, Any] = field(default_factory=dict) 


@dataclass
class PlanTrace:
    """
    Represents the complete execution trace of a reasoning plan.
    This is the primary input for the EpistemicTraceEncoder and subsequently 
    the Epistemic Plan HRM model.
    """
    # --- Core Identifiers ---
    trace_id: str # Unique identifier for this specific trace/execution
    
    # --- Initial Context ---
    goal_text: str # The original goal or query
    goal_embedding: List[float] # The embedding vector for the goal_text
    input_data: Dict[str, Any] # Any initial data or variables provided to the plan
    
    # --- Plan Definition (Optional but useful for context) ---
    # This could be a representation of the DSPy program or pipeline used.
    # A simple string signature or a more structured representation.
    plan_signature: str 

    # --- Execution Details ---
    execution_steps: List[ExecutionStep] # The sequence of steps executed
    
    # --- Final Outcome ---
    final_output_text: str # The final output produced by the plan
    # The scores assigned to the final output by various scorers.
    final_scores: ScoreBundle 
    # Optional: Embedding of the final_output_text. Can be computed on demand.
    final_output_embedding: Optional[List[float]] = None 

    # --- Target for Epistemic Plan HRM Training ---
    # This is the label the HRM model will try to predict.
    # It represents the "epistemic quality" of this reasoning process.
    target_epistemic_quality: Optional[float] = None 
    # Source of the target quality score (e.g., "llm_judgment", "proxy_metric_avg_sicql_q")
    target_epistemic_quality_source: Optional[str] = None 

    # --- Metadata ---
    created_at: str = "" # ISO format timestamp
    # Any other execution metadata (e.g., time taken, DSPy optimizer version)
    meta: Dict[str, Any] = field(default_factory=dict) 

    # --- Utility Methods ---
    def get_all_text_outputs(self) -> List[str]:
        """Get a list of all text outputs, including intermediate steps and final output."""
        texts = [step.output_text for step in self.execution_steps]
        texts.append(self.final_output_text)
        return texts

    def get_all_score_bundles(self) -> List[ScoreBundle]:
        """Get a list of all ScoreBundles, including intermediate steps and final output."""
        bundles = [step.scores for step in self.execution_steps]
        bundles.append(self.final_scores)
        return bundles

    # Note: Methods to calculate proxy metrics for target_epistemic_quality 
    # could be added here or in a separate utility function.
    # def calculate_proxy_quality_score(self, method: str = "avg_sicql_q") -> float: ...

# Example (Conceptual) Usage:
# This is how data might be structured when passed to the encoder.
# In practice, this would be populated by the EpistemicPlanExecutorAgent or similar.

# example_trace = PlanTrace(
#     trace_id="trace_12345",
#     goal_text="Explain the benefits of renewable energy.",
#     goal_embedding=[0.1, -0.2, ..., 0.5], # (embedding_dim,) list
#     input_data={}, # No specific input data in this example
#     plan_signature="DSPy_Signature(generate_answer)",
#     execution_steps=[
#         ExecutionStep(
#             step_id="step_1",
#             description="Retrieve documents about renewable energy.",
#             output_text="Doc1: Solar panels convert sunlight...\nDoc2: Wind turbines use wind...",
#             scores=ScoreBundle({...}) # Containing SICQL, EBT, etc. scores for the output text vs goal
#         ),
#         ExecutionStep(
#             step_id="step_2",
#             description="Analyze retrieved documents.",
#             output_text="Key points: Solar and wind are major renewable sources...",
#             scores=ScoreBundle({...}) # Scores for this intermediate summary vs goal
#         ),
#         # ... more steps ...
#     ],
#     final_output_text="Renewable energy offers benefits like sustainability...",
#     final_scores=ScoreBundle({...}), # Scores for the final output vs goal
#     target_epistemic_quality=0.85, # Assigned during data preparation (e.g., LLM judgment)
#     target_epistemic_quality_source="llm_judgment_detailed",
#     created_at="2023-10-27T10:00:00Z",
#     meta={"execution_time_ms": 1250, "dspy_optimizer": "BootstrapFewShot"}
# )
