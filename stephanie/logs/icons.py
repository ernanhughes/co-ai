def get_event_icon(event_type: str) -> str:
    """Get the icon associated with a specific event type."""
    return EVENT_ICONS.get(event_type, "â“")  # Default: question mark


# ========================
# SYSTEM & INITIALIZATION
# ========================
SYSTEM_INIT = {
    "AgentInitialized": "ğŸ¤–",                 # Agent initialization
    "AgentInit": "ğŸ¤–",                        # Agent startup
    "ContextLoaded": "ğŸ“‚",                    # Context loaded
    "ContextSaved": "ğŸ’¾",                     # Context saved
    "SupervisorComponentsRegistered": "ğŸ‘¨â€ğŸ«",  # Supervisor registration
    "DomainClassifierInit": "ğŸ·ï¸ğŸ§ ",           # Domain classifier init
    "DomainConfigLoaded": "ğŸ·ï¸ğŸ“‹",            # Domain config loaded
    "SeedEmbeddingsPrepared": "ğŸŒ±ğŸ§¬",          # Seed embeddings prepared
}

# =================
# KNOWLEDGE STORAGE
# =================
KNOWLEDGE_OPS = {
    "CartridgeCreated": "ğŸ’¾ğŸ“¦",                # Cartridge created
    "CartridgeAlreadyExists": "ğŸ’¾âœ…",          # Cartridge exists check
    "TriplesAlreadyExist": "ğŸ”—âœ…",            # Triples exist check
    "DimensionEvaluated": "ğŸ“âœ…",            # Dimension evaluated All right thanks Dan Dance Engineer the dance
    "CartridgeDomainInserted": "ğŸ’¾ğŸ·ï¸",         # Cartridge domain added
    "TripleInserted": "ğŸ”—",                   # Triple inserted
    "SectionInserted": "ğŸ“‚â•",                 # Section inserted
    "TripletScored": "ğŸ”—ğŸ“Š",                  # Triplet scored
    "SectionDomainInserted": "ğŸ“‚ğŸ·ï¸",          # Section domain added
    "SectionDomainUpserted": "ğŸ“‚ğŸ”„",           # Section domain updated
    "DocumentAlreadyExists": "ğŸ“„âœ…",           # Document exists check
    "DomainUpserted": "ğŸ·ï¸ğŸ”„",                 # Domain updated
    "ContextYAMLDumpSaved": "ğŸ“„ğŸ’¾",            # YAML context saved
}

# =================
# PIPELINE CONTROL
# =================
PIPELINE_FLOW = {
    "PipelineStart": "ğŸš¦â–¶ï¸",                  # Pipeline started
    "PipelineStageStart": "â©",               # Stage started
    "PipelineStageEnd": "â¹ï¸",                # Stage completed
    "PipelineStageSkipped": "â­ï¸",            # Stage skipped
    "PipelineIterationStart": "ğŸ”„â–¶ï¸",          # Iteration started
    "PipelineIterationEnd": "ğŸ”„â¹ï¸",           # Iteration completed
    "PipelineSuccess": "âœ…",                  # Pipeline succeeded
    "PipelineError": "âŒ",                    # Pipeline error
    "PipelineRunInserted": "ğŸ”ğŸ’¾",            # Pipeline run saved
    "AgentRunStarted": "ğŸ¤–â–¶ï¸",                # Agent run started
    "AgentRunCompleted": "ğŸ¤–â¹ï¸",             # Agent run completed
    "AgentRanSuccessfully": "ğŸ¤–âœ…",           # Agent succeeded
    "PipelineJudgeAgentEnd": "âš–ï¸â¹ï¸",         # Judge agent completed
}

# =====================
# SCORING & EVALUATION
# =====================
SCORING = {
    "DocumentScored": "ğŸ“Šâœ…",                 # Document scored
    "HypothesisScored": "ğŸ’¡ğŸ“Š",               # Hypothesis scored
    "ScoreComputed": "ğŸ§®âœ…",                  # Score computed
    "ScoreParsed": "ğŸ“ğŸ“Š",                    # Score parsed
    "ScoreSaved": "ğŸ’¾ğŸ“Š",                     # Score saved
    "ScoreSavedToMemory": "ğŸ§ ğŸ’¾",             # Score saved to memory
    "ScoreSkipped": "â­ï¸ğŸ“Š",                 # Scoring skipped
    "ScoreDelta": "ğŸ“ˆ",                      # Score delta
    "ScoreCacheHit": "ğŸ’¾âœ…",                  # Score cache hit
    "MRQScoreBoundsUpdated": "ğŸ“ˆğŸ”„",         # MRQ bounds updated
    "MRQDimensionEvaluated": "ğŸ“ğŸ§ ",          # Dimension evaluated
    "CorDimensionEvaluated": "ğŸ“âœ…",          # COR dimension evaluated
    "MRQScoringComplete": "ğŸ“Šâœ…",             # MRQ scoring complete
}

# =====================
# REASONING & ANALYSIS
# =====================
REASONING = {
    "KeywordsExtracted": "ğŸ”‘",                # Keywords extracted
    "ProximityAnalysisScored": "ğŸ“ŒğŸ—ºï¸",        # Proximity analysis
    "ProximityGraphComputed": "ğŸ“ŠğŸŒ",         # Proximity graph
    "HypothesisJudged": "âš–ï¸",                # Hypothesis judged
    "SymbolicAgentRulesFound": "ğŸ§©ğŸ”",        # Symbolic rules found
    "SymbolicAgentOverride": "ğŸ§ ğŸ”„",          # Symbolic override
    "RuleApplicationLogged": "ğŸ§¾ğŸ§©",          # Rule application logged
    "RuleApplicationUpdated": "ğŸ”„ğŸ§©",         # Rule application updated
    "RuleApplicationCount": "ğŸ”¢ğŸ§©",           # Rule applications counted
    "RuleApplicationsScored": "ğŸ¯ğŸ§©",         # Rule applications scored
    "NoSymbolicAgentRulesApplied": "ğŸš«ğŸ§©",    # No rules applied
    "SymbolicAgentNewKey": "ğŸ”‘ğŸ§ ",            # New symbolic key
    "SymbolicPipelineSuggestion": "ğŸ’¡ğŸ§©",     # Symbolic pipeline suggestion
}

# =====================
# TRAINING & MODEL OPS
# =====================
TRAINING = {
    "MRQTrainerStart": "ğŸš€ğŸ§ ",                # MRQ training started
    "MRQTrainerTrainingComplete": "ğŸ“ğŸ§ ",     # MRQ training completed
    "MRQModelInitializing": "ğŸ§ âš™ï¸",          # MRQ model initializing
    "TrainingEpoch": "ğŸ‹ï¸",                   # Training epoch
    "TrainingComplete": "ğŸ“âœ…",              # Training completed
    "TrainingDataProgress": "ğŸ“ˆğŸ”„",           # Training data progress
    "RegressionTunerFitted": "ğŸ“ˆğŸ”§",          # Regression tuner fitted
    "RegressionTunerTrainSingle": "ğŸ”§â–¶ï¸",     # Tuner training
    "DocumentTrainingComplete": "ğŸ“„ğŸ“",       # Document training completed
    "DocumentPairBuilderComplete": "ğŸ“‘âœ…",    # Document pairs built
    "DocumentMRQTrainerEpoch": "ğŸ“ŠğŸ‹ï¸",      # Document MRQ epoch
    "DocumentMRQTrainingStart": "ğŸš€ğŸ“Š",       # Document MRQ training start
    "DocumentTrainingProgress": "ğŸ“ˆğŸ”„",       # Training progress
    "DocumentMRQTrainDimension": "ğŸ§©ğŸ“Š",      # Dimension training
    "DocumentPairBuilderProgress": "ğŸ“ŠğŸ“‘",    # Pair building progress
}

PROMPTS = {
    "PromptLoaded": "ğŸ“„âœ…",                   # Prompt loaded
    "PromptStored": "ğŸ’¾ğŸ“„",                   # Prompt stored
    "PromptExecuted": "ğŸ’¬â–¶ï¸",                 # Prompt executed
    "PromptFileLoading": "ğŸ“„ğŸ”„",            # Prompt file loading
    "PromptFileLoaded": "ğŸ“„âœ…",              # Prompt file loaded
}

# ==================
# HYPOTHESIS WORKFLOW
# ==================
HYPOTHESIS_OPS = {
    "GoalCreated": "ğŸ¯âœ¨",                   # Goal created
    "GoalDomainAssigned": "ğŸ¯ğŸ·ï¸",           # Goal domain assigned
    "GeneratedHypotheses": "ğŸ’¡âœ¨",            # Hypotheses generated
    "HypothesisStored": "ğŸ’¾ğŸ’¡",              # Hypothesis stored
    "HypothesisInserted": "ğŸ“¥ğŸ’¡",            # Hypothesis inserted
    "HypothesisStoreFailed": "âŒğŸ’¡",          # Hypothesis store failed
    "EvolvingTopHypotheses": "ğŸ”„ğŸ’¡",          # Hypotheses evolving
    "EvolvedHypotheses": "ğŸŒ±ğŸ’¡",             # Hypotheses evolved
    "GraftingPair": "ğŸŒ¿â•",                  # Hypothesis grafting
    "EditGenerated": "âœï¸",                  # Hypothesis edit
    "SimilarHypothesesFound": "ğŸ”ğŸ’¡",        # Similar hypotheses found
    "NoHypothesesInContext": "ğŸš«ğŸ’¡",         # No hypotheses found
}

# =================
# RESEARCH & DATA
# =================
RESEARCH = {
    "ArxivSearchStart": "ğŸ”ğŸ“š",              # Arxiv search started
    "ArxivSearchComplete": "âœ…ğŸ“š",           # Arxiv search completed
    "ArxivQueryFilters": "âš™ï¸ğŸ”",            # Arxiv filters applied
    "DocumentsToJudge": "ğŸ“„âš–ï¸",             # Documents to judge
    "DocumentsFiltered": "ğŸ“‘ğŸ”",             # Documents filtered
    "LiteratureSearchCompleted": "âœ…ğŸ“š",      # Literature search completed
    "LiteratureSearchSkipped": "â­ï¸ğŸ“š",      # Literature search skipped
    "SearchingWeb": "ğŸŒğŸ”",                 # Web search in progress
    "SearchResult": "ğŸ”ğŸ“„",                 # Search result found
    "NoResultsFromWebSearch": "ğŸŒğŸš«",        # No search results
    "DocumentProfiled": "ğŸ“„ğŸ“‹",             # Document profiled
    "DocumentProfileFailed": "ğŸ“„âŒ",         # Document profile failed
}

# ===================
# DEBUG & DIAGNOSTICS
# ===================
DEBUGGING = {
    "debug": "ğŸ",                          # Debug message
    "NodeDebug": "ğŸŒ²ğŸ”",                    # Node debugging
    "NodeSummary": "ğŸŒ²ğŸ“",                 # Node summary
    "StageContext": "ğŸ”§ğŸ“‹",                # Stage context
    "TrimmingSection": "âœ‚ï¸",               # Section trimming
    "ContextAfterStage": "ğŸ—ƒï¸â¡ï¸",          # Post-stage context
    "PipelineScoreSummary": "ğŸ“ŠğŸ§¾",        # Pipeline score summary
    "ClassificationStarted": "ğŸ·ï¸â–¶ï¸",      # Classification started
    "ClassificationCompleted": "ğŸ·ï¸âœ…",    # Classification completed
}

# ======================
# ERROR & WARNING STATES
# ======================
ERROR_STATES = {
    "PipelineError": "âš ï¸",                  # Pipeline error
    "DocumentLoadFailed": "âŒğŸ“„",           # Document load failed
    "LiteratureQueryFailed": "âŒğŸ“š",        # Literature query failed
    "HypothesisStoreFailed": "âŒğŸ’¾",        # Hypothesis store failed
    "PromptLoadFailed": "âŒğŸ“",            # Prompt load failed
    "PromptParseFailed": "âŒğŸ“",           # Prompt parse failed
    "PromptEvaluationFailed": "âŒğŸ“",      # Prompt evaluation failed
    "TrainingError": "âŒğŸ‹ï¸",              # Training error
    "PreferencePairSaveError": "âŒğŸ’¾",     # Preference save error
    "RefinerError": "âŒğŸ”„",               # Refiner error
    "DocumentMRQModelMissing": "âŒğŸ§ ",    # MRQ model missing
    "DocumentMRQTunerMissing": "âŒğŸ”§",    # MRQ tuner missing
    "TunedPromptGenerationFailed": "âŒğŸ”„ğŸ“", # Tuned prompt failed
    "InvalidRuleMutation": "âŒğŸ§¬",         # Invalid rule mutation
}

# =============
# SPECIAL CASES
# =============
SPECIAL = {
    "SQLQuery": "ğŸ’¾ğŸ”",                    # SQL query executed
    "EthicsReviewsGenerated": "âš–ï¸ğŸ§¾",      # Ethics reviews generated
    "SurveyAgentSkipped": "â­ï¸ğŸ“‹",         # Survey skipped
    "EarlyStopping": "ğŸ›‘â±ï¸",              # Early stopping triggered
    "SharpenedHypothesisSaved": "ğŸ’ğŸ’¾",    # Sharpened hypothesis saved
    "CoTGenerated": "â›“ï¸ğŸ’­",               # Chain-of-Thought generated
    "LLMCacheHit": "ğŸ’¾âš¡",                # LLM cache hit
}

# Combine all categories into a single dictionary
EVENT_ICONS = {
    **SYSTEM_INIT,
    **KNOWLEDGE_OPS,
    **PIPELINE_FLOW,
    **SCORING,
    **REASONING,
    **TRAINING,
    **HYPOTHESIS_OPS,
    **RESEARCH,
    **DEBUGGING,
    **ERROR_STATES,
    **SPECIAL,
    **PROMPTS,
}