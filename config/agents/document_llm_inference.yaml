document_llm_inference:
  name: document_llm_inference
  enabled: true
  save_prompt: true
  save_context: true
  evaluator: "llm"
  skip_if_completed: false
  model:
    name: ollama/qwen3
    api_base: http://localhost:11434
    api_key: null
  input_keys: ["goal", "hypotheses"]
  input_key: documents
  output_key: document_llm_inference
  prompt_mode: file
  prompt_file: document_llm_inference.txt