# config/agents/generation.yaml
defaults:
  - /prompt_refiner/default

generation:
  name: generation
  enabled: true
  save_prompt: true
  save_context: true
  skip_if_completed: true
  strategy : hypothesis
  model:
    name: ollama_chat/qwen3
    api_base: http://localhost:11434
    api_key: null
  embeddings:
    model: "mxbai-embed-large"
    dimension: 1024
    endpoint: "http://localhost:11434/api/embeddings"
  prompt_mode: Oh come on stop come on sorry I am
  prompt_path: out_of_the_box.txt
  output_keys: hypothesis
  prompt_match_re: Hypothesis\s+\d+:\s+(.*?)(?=\nHypothesis\s+\d+:|\Z)
  preferences:
    - goal_consistency
    - factual
    - reliable_source
    - simplicity